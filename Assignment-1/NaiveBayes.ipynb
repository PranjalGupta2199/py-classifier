{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rppR4eRcHPEG"
   },
   "outputs": [],
   "source": [
    "with open(\"a1_d3.txt\", \"r\") as text_file:\n",
    "        data = text_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PGRYPB36HZmX"
   },
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    processing_data=[]\n",
    "    for single_data in data:       \n",
    "        if len(single_data.split(\"\\t\"))==2 and single_data.split(\"\\t\")[1]!=\"\":\n",
    "            processing_data.append(single_data.split(\"\\t\")) #split data on tab\n",
    "    return processing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CM7EKdh3bY10"
   },
   "outputs": [],
   "source": [
    "values=preprocessing_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zV5COg9hi1d6"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "new_data=[]\n",
    "for i in values:\n",
    "  i[0]=i[0].lower() #Convert all upper characters to lower characters\n",
    "  i[0]=re.sub(r'\\d+', '', i[0]) #Remove all numbers\n",
    "  i[0]=i[0].translate(str.maketrans('', '', string.punctuation)) #Remove all punctuation\n",
    "  new_data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W9IHxXxEHdAx"
   },
   "outputs": [],
   "source": [
    "#5 fold cross-validation\n",
    "crossvalidationtestset={}\n",
    "crossvalidationdataset={}\n",
    "size=len(values)\n",
    "for i in range(5):\n",
    "  crossvalidationtestset[i]=values[(int)(i*size/5):(int)((i+1)*size/5)]\n",
    "  crossvalidationdataset[i]=values[0:(int)((i)*size/5)]+values[(int)((i+1)*size/5):size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FhppnTmVkGNA"
   },
   "outputs": [],
   "source": [
    "def make_dataset(values):\n",
    "  no_items={}\n",
    "  dataset={}\n",
    "  #no_items={'0':  ,'1':  }\n",
    "  #dataset={'word1':{'0':  ,'1':  },'word2':{'0':  ,'1':  }... }\n",
    "  #no_items has total no. of words in category 0 and category and 1\n",
    "  #dataset has no. of appearances of word in each category\n",
    "  for i in range(len(values)):\n",
    "    no_items.setdefault(values[i][1],0)\n",
    "    no_items[values[i][1]]+=1\n",
    "    splitdata=values[i][0].split() #Split line into words\n",
    "    for j in range(len(splitdata)):\n",
    "      dataset.setdefault(splitdata[j],{})\n",
    "      dataset[splitdata[j]].setdefault(values[i][1],0)\n",
    "      dataset[splitdata[j]][values[i][1]]+=1\n",
    "  return dataset, no_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-GO1HL5Hj2y"
   },
   "outputs": [],
   "source": [
    "def calc_prob(word,category,dataset,no_of_items):\n",
    "\t#Assign probability value zero if it cannot be calculated\n",
    "\tif word not in dataset or category not in dataset[word]:\n",
    "\t\treturn 0\n",
    "\treturn float(dataset[word][category])/no_of_items[category]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3tmVr58nR_SA"
   },
   "outputs": [],
   "source": [
    "# Weighted probability of a word for a category\n",
    "def weighted_prob(word,category,dataset,no_of_items):\n",
    "\t# basic probability of a word\n",
    "\tbasic_prob=calc_prob(word,category,dataset,no_of_items)\n",
    "\ttot=0\n",
    "\tif word in dataset:\n",
    "\t\tif '0' in dataset[word]:\n",
    "\t\t\ttot+=dataset[word]['0']\n",
    "\t\tif '1' in dataset[word]:\n",
    "\t\t\ttot+=dataset[word]['1']\n",
    "\t#default probability of a word is taken as 0.5\n",
    "\t#default appearnaces are also taken as 1\n",
    "\t#weights are taken as total no. of appearnaces\n",
    "\tweight_prob=((1.0*0.5)+(tot*basic_prob))/(1.0+tot)\n",
    "\treturn weight_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZVqtyl4MSvR"
   },
   "outputs": [],
   "source": [
    "def test_prob(test,category,dataset,no_of_items):\n",
    "# To get p(test data | category)\t\n",
    "\tsplit_data=test.split() #Split line into words\n",
    "\tp=1\n",
    "\tfor i in split_data:\n",
    "\t\tp*=weighted_prob(i,category,dataset,no_of_items)\n",
    "\treturn p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qO1en7diK0BG"
   },
   "outputs": [],
   "source": [
    "def naive_bayes(test,dataset,no_of_items):\n",
    "  #NAIVE BAYES FUNCTION\n",
    "\t\t#p(A|B) = p(B|A) * p(A)/p(B)\n",
    "\t\t#A :- Probably of being Category(0/1)\n",
    "\t\t#B :- Test data\n",
    "\t\t#p(A|B) :- Category given the Test data\n",
    "\t\t#Ignore p(B) in the denominator since it doesn't change\n",
    "\tresults={}\n",
    "\tcategory=['0','1']\n",
    "\tfor i in category:\n",
    "\t\t# Category Probability\n",
    "\t\tcategory_prob=float((no_of_items[i])/(no_of_items['0']+no_of_items['1']))\n",
    "    # Number of items in category/total number of items\n",
    "\n",
    "\t\t# p(test data | category)\n",
    "\t\ttest_prob1=test_prob(test,i,dataset,no_of_items)\n",
    "\t\tresults[i]=test_prob1*category_prob\n",
    "\treturn results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UP8n1Sc-VucR"
   },
   "outputs": [],
   "source": [
    "def compute_tp_tn_fn_fp(y_act,y_pred):\n",
    "  tp=0 # tp: true positive\n",
    "  fp=0 # fp: false positive\n",
    "  fn=0 # fn: false negative\n",
    "  tn=0 # tn: true negative\n",
    "  size=len(y_act)\n",
    "  for i in range(size):\n",
    "    if((y_act[i]==1)&(y_pred[i]==1)):\n",
    "        tp+=1\n",
    "    elif((y_act[i]==0)&(y_pred[i]==0)):\n",
    "        tn+=1\n",
    "    elif((y_act[i]==0)&(y_pred[i]==1)):\n",
    "        fp+=1\n",
    "    elif((y_act[i]==1)&(y_pred[i]==0)):\n",
    "        fn+=1\n",
    "  return tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranjal/.local/share/virtualenvs/py-classifier-DqgJ-lTA/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZ2C9NgQTycU"
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy={}\n",
    "precision={}\n",
    "recall={}\n",
    "f_score={}\n",
    "for i in range(5):\n",
    "  dataset, no_of_items= make_dataset(crossvalidationdataset[i])\n",
    "  for x in range(len(crossvalidationtestset[i])):\n",
    "    result=naive_bayes(crossvalidationtestset[i][x][0],dataset,no_of_items)\n",
    "    if result['1'] > result['0']:\n",
    "\t    crossvalidationtestset[i][x].append(1)\n",
    "    else:\n",
    "\t    crossvalidationtestset[i][x].append(0)\n",
    "  y_act=[row[1] for row in crossvalidationtestset[i]]\n",
    "  y_act=[int(i) for i in y_act]\n",
    "  y_pred=[row[2] for row in crossvalidationtestset[i]]\n",
    "  y_pred=[int(i) for i in y_pred]\n",
    "  y_act1=pd.DataFrame(y_act)\n",
    "  y_pred1=pd.DataFrame(y_pred)\n",
    "  tp, tn, fp, fn= compute_tp_tn_fn_fp(y_act,y_pred) \n",
    "  accuracy[i]=((tp+tn)*100)/float(tp+tn+fn+fp)\n",
    "  precision[i]=(tp*100)/float(tp+fp)\n",
    "  recall[i]=(tp*100)/float(tp+fn)\n",
    "  f_score[i]=(2*precision[i]*recall[i])/(precision[i] + recall[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGi_hVM1iQF2"
   },
   "outputs": [],
   "source": [
    "\n",
    "meanaccuracy=0\n",
    "for i in range(5):\n",
    "  meanaccuracy+=accuracy[i]\n",
    "meanf_score=0\n",
    "meanaccuracy/=5\n",
    "for i in range(5):\n",
    "  meanf_score+=f_score[i]\n",
    "meanf_score/=500\n",
    "stddevaccuracy=0\n",
    "stddevf_score=0\n",
    "for i in range(5):\n",
    "  stddevaccuracy+=(accuracy[i]-meanaccuracy)**2\n",
    "stddevaccuracy/=5\n",
    "stddevaccuracy=math.sqrt(stddevaccuracy)\n",
    "for i in range(5):\n",
    "  stddevf_score+=(f_score[i]/100-meanf_score)**2\n",
    "stddevf_score/=5\n",
    "stddevf_score=math.sqrt(stddevf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1744,
     "status": "ok",
     "timestamp": 1588179517512,
     "user": {
      "displayName": "Simran sandhu",
      "photoUrl": "",
      "userId": "15531787810630485221"
     },
     "user_tz": -330
    },
    "id": "DxI2Husvi-wc",
    "outputId": "8b001795-e95c-4bae-88bb-c9c63f9b71ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ans 76.9 +- 1.9339079605813714\n",
      "Ans 0.7738388767626625 +- 0.02527368677944865\n"
     ]
    }
   ],
   "source": [
    "print(\"Ans\",meanaccuracy,\"+-\",stddevaccuracy)\n",
    "print(\"Ans\",meanf_score,\"+-\",stddevf_score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN66v6g25Z5nCKuIovFnQp7",
   "collapsed_sections": [],
   "name": "NaiveBayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('py-classifier': pipenv)",
   "language": "python",
   "name": "python37464bitpyclassifierpipenv9ae3f59e53a24f77ad0473627020120e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
